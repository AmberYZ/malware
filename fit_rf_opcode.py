'''
Fit random forest model on the opcode counts features
'''
import ConfigParser
from sklearn import cross_validation
from sklearn.cross_validation import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import f1_score
from sklearn.metrics import make_scorer
from sklearn.metrics import roc_curve,auc
import cPickle
import csv
import multiprocessing
import numpy as np
import os
import re
import string
import sys

train_label = []

#Loading configuration file
Config = ConfigParser.ConfigParser()
Config.read("/home/amber/Malware/config")
path_data = Config.get("Train","feature_save")
path_label = Config.get("Train","label")
path_save = Config.get("Train","model")


subset = 10000 #Using subset of data to fit the model

#Loading trainning labels
label_count = 0      
with open(path_label) as f:
    for line in f:
        label_count+=1
        line = line.split(",")

        train_label.append(line[1].strip()) 
        if(label_count == subset):
            break
print("Trainning labels loading completed: "+str(len(train_label)))


def fit_rf(ngram, n):
    #Loading the Trainning data
    train_data = []
    import_count= 0
    data_count = 0
    ngram_name = str(ngram.split("_")[0])+"_"+str(ngram.split("_")[1])+"_count.csv"
    with open(os.path.join(path_data,ngram_name)) as f:
        reader = csv.reader(f,delimiter=",")
        for line in reader:
            import_count+=1
            if(import_count>1):
                data_import = []
                try:
                    line[-1] = line[-1].strip()
                    data_import = [int(0) if not x else float(x) for x in line]
                except:
                    print(data_import)
                    break
                train_data.append(data_import)
                data_count+=1
            #if(data_count%1000==0):
                #print("Loading: "+str(ngram_name)+" "+str(data_count))

            sys.stdout.write('\r' + "Loading: "+str(ngram_name)+" "+str(data_count)+'\n')
            sys.stdout.flush() 
                

            if(data_count==subset):
                break

    #Fitting the model 
    print("Fitting rf model on "+ngram)
    X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.33, random_state=42)
    rf = RandomForestClassifier(n_estimators=n,n_jobs = 300)
    rf.fit(X_train,y_train)
    print("Evaluating model on "+ngram)
    print(rf.score(X_train,y_train))
    print(rf.score(X_test,y_test))
    print("Saving rf model: "+ngram_name)
    model_name = str(ngram.split("_")[0])+"_"+str(ngram.split("_")[1])+"_rf.pkl"

    #Save the random forest model for later evaluation
    with open(os.path.join(path_save,model_name), 'wb+') as fid:
        cPickle.dump(rf, fid) 
        print("Model saving completed: "+ngram)


def main():

    one = multiprocessing.Process(target=fit_rf,args=("one_gram",300))
    two = multiprocessing.Process(target=fit_rf,args=("two_gram",300))
    three = multiprocessing.Process(target=fit_rf,args=("three_gram",300))
    four = multiprocessing.Process(target=fit_rf,args=("four_gram",300))
    five = multiprocessing.Process(target=fit_rf,args=("five_gram",300))
    #one.start()
    #two.start()
    #three.start()
    four.start()
    #five.start()

if __name__ == '__main__':
    main()

