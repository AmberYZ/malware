'''
Train the xgboost model
'''
import ConfigParser
import cPickle
import csv
import numpy as np
import os
import re
import string
import sys

train_data = []
train_label = []

Config = ConfigParser.ConfigParser()
Config.read("/home/amber/Malware/config")
path_data = Config.get("Train","feature_save")
path_opcode = Config.get("Train","feature_save")
path_label = Config.get("Train","label")
path_save = Config.get("Train","md")


def find_idx(total, select):
    result = []
    for item in select:
        try:
            result.append(total.index(item))
        except:
            print(item+"not in trainning attributes")
    return result


subset =10000

#Loading selected features

def load_selected_features(file):
    with open(file) as f:
        for line in f:
            line = line.split(",")
            line[-1] =  line[-1].strip()
            return line
            break


#Loading trainning labels
label_count = 0      
with open(path_label) as f:
    for line in f:
        label_count+=1
        line = line.split(",")

        train_label.append(line[1].strip()) 
        if(label_count == subset):
            break
print("Trainning labels loading completed: "+str(len(train_label)))


#Loading selected n_Gram opcode data
#ngram = ["one"]
ngram = ["one","two","three","four"]
gram_count = 0
for gram in ngram:
    gram_count +=1
    import_count = 0
    data_count = 0
    select_features_idx = []

    with open(os.path.join(path_opcode,gram+"_gram_count.csv")) as f:
        for line in f:
            import_count+=1
            data = line.split(",")
            data[-1] = data[-1].strip()  
            if(import_count==1):
                #Get selected features for nGram
                selected = load_selected_features("/data/trend/md/"+gram+"_gram_selected.csv")
                #print("Selecting "+gram+" "+str(len(selected))+ " opcode features")
                select_features_idx = find_idx(data,selected)
            data = [data[x] for x in select_features_idx]
            if(import_count>1):
                data = [int(0) if not x else float(x) for x in data]
                if(gram_count==1):
                    train_data.append(data)
                else:
                    train_data[data_count].extend(data)
                data_count+=1
            sys.stdout.write('\r' + "Loading "+gram+" gram opcode data: "+str(data_count)+' '*20)
            sys.stdout.flush() 

            if(data_count==subset):
                print("\n"+"Loading opcode complete")
                break

#Loading hex count data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"organized_hex.csv")) as f:
    for line in f:
        line = line.strip()
        import_count += 1
        data_import = line.split(",")
        data_import[-1] = data_import[-1].strip()
        if(import_count==1):
            #Get selected features 
            data_import[-1]="ff"
            selected = load_selected_features("/data/trend/md/selected_hex.csv")
            #print("Selecting "+str(len(selected))+ " hex features")
            select_features_idx = find_idx(data_import,selected)
        
        if(import_count>2):
            data_import = [data_import[x] for x in select_features_idx]
            data_import = [int(0) if not x else float(x) for x in data_import]
            train_data[data_count].extend(data_import)
            data_count+=1
        sys.stdout.write('\r' + "Loading hex data: "+str(data_count)+' '*20)
        sys.stdout.flush() 

        if(data_count==subset):
            print("\n"+"Loading hex complete")
            break
#Loading memory_count data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"memory.csv")) as f:
    for line in f:
        line = line.strip()
        import_count += 1
        data_import = line.split(",")
        data_import[-1] = data_import[-1].strip()
        if(import_count==1):
            #Get selected features 
            selected = load_selected_features("/data/trend/md/selected_memory.csv")
            #print("Selecting "+str(len(selected))+ " memory features")
            select_features_idx = find_idx(data_import,selected)
        data_import = [data_import[x] for x in select_features_idx]
        if(import_count>1):
            data_import = [int(0) if not x else float(x) for x in data_import]
            #train_data.append(data_import)
            train_data[data_count].extend(data_import)
            data_count+=1
        sys.stdout.write('\r' + "Loading memory_word data: "+str(data_count)+' '*20)
        sys.stdout.flush() 

        if(data_count==subset):
            print("\n"+"Loading memory complete")
            break



#Loading info data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"organized_info.csv")) as f:
     for line in f:
        data_import = line.split(",")
        if(data_import[0]=='"' and len(data_import)==1):
            pass
        else:
            import_count += 1
        if(import_count==1):
            #Get selected features 
            data_import[-1] = data_import[-1].strip()
            selected = load_selected_features("/data/trend/md/selected_info.csv")
            #print("Selecting "+str(len(selected))+ " info features")
            select_features_idx = find_idx(data_import,selected)
        data_import = [data_import[x] for x in select_features_idx]
  
        if(import_count>1):

            if("#DIV/0!" in data_import):
                data_import = [0 if x=="#DIV/0!" else x for x in data_import]
            data_import = [int(0) if not x else float(x) for x in data_import]
            train_data[data_count].extend(data_import)
            data_count+=1
            
        sys.stdout.write('\r' + "Loading info data: "+str(data_count)+' '*20)
        sys.stdout.flush() 
        if(data_count==subset):
            print("\n"+"Loading info complete")
            break

#Loading import data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"organized_import")) as f:
    reader = csv.reader(f,delimiter="\t")
    for line in reader:
        import_count+=1
        if(import_count==1):
            #Get selected features 
            selected = load_selected_features("/data/trend/md/selected_import.csv")
            #print("Selecting "+str(len(selected))+ " import features")
            select_features_idx = find_idx(line,selected)
        line = [line[x] for x in select_features_idx]
  
        if(import_count>1):
            try:
                line[-1] = line[-1].strip()
                data_import = [int(0) if not x else float(x) for x in line]
            except:
                print(data_import)
                break
            train_data[data_count].extend(data_import)
            data_count+=1
        sys.stdout.write('\r' + "Loading import data: "+str(data_count)+' '*20)
        sys.stdout.flush() 
        if(data_count==subset):
            print("\n"+"Loading info complete")
            break

# #Loading section data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"organized_section")) as f:
    reader = csv.reader(f,delimiter="\t")
    for line in reader:
        import_count+=1
        if(import_count==1):
            #Get selected features 
            selected = load_selected_features("/data/trend/md/selected_section.csv")
            #print("Selecting "+str(len(selected))+ " section features")
            select_features_idx = find_idx(line,selected)
        line = [line[x] for x in select_features_idx]
#   
        if(import_count>1):
            data_import = [int(0) if not x else float(x) for x in line]
            train_data[data_count].extend(data_import)
            data_count+=1
        sys.stdout.write('\r'+"Loading section data: "+str(data_count)+' '*20)
        sys.stdout.flush()
        if(data_count==subset):
            print("\n"+"Loading section complete")
            break


#Loading asm image data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"image.csv")) as f:
     for line in f:
        data_import = line.split(",")
        import_count += 1

        if(import_count==1):
            #Get selected features 
            selected = load_selected_features("/data/trend/md/selected_image.csv")
            #print("Selecting "+str(len(selected))+ " image features")
            select_features_idx = find_idx(data_import,selected)
        data_import = [data_import[x] for x in select_features_idx]

        if(import_count>1):
            if('nan' in data_import):
                data_import = [0 if x.strip()=='nan' else x for x in data_import]
            try:
                data_import[-1] = data_import[-1].strip()
            except:
                pass
            train_data[data_count].extend(data_import)

            data_count+=1
        sys.stdout.write('\r'+"Loading asm image data: "+str(data_count)+' '*20)
        sys.stdout.flush()
        if(data_count==subset):
            print("\n"+"Loading image complete")
            break

#Loading asm image stat data
import_count = 0
data_count = 0
with open(os.path.join(path_data,"image_stat.csv")) as f:
     for line in f:
        data_import = line.split(",")
        import_count += 1

        if(import_count==1):
            data_import[-1] = data_import[-1].strip()
            #Get selected features 
            selected = load_selected_features("/data/trend/md/selected_image_stat.csv")
            #print("Selecting "+str(len(selected))+ " image features")
            select_features_idx = find_idx(data_import,selected)
        data_import = [data_import[x] for x in select_features_idx]

        if(import_count>1):
            if('nan' in data_import):
                data_import = [0 if x.strip()=='nan' else x for x in data_import]
            try:
                data_import[-1] = data_import[-1].strip()
            except:
                pass
            train_data[data_count].extend(data_import)

            data_count+=1
        sys.stdout.write('\r'+"Loading asm image stat data: "+str(data_count)+' '*20)
        sys.stdout.flush()
        if(data_count==subset):
            print("\n"+"Loading image stast complete")
            break


#Trainning the model
#Total 504 features
from sklearn.ensemble import RandomForestClassifier
from sklearn.cross_validation import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn import cross_validation
import cPickle
import xgboost as xgb
from sklearn.metrics import roc_curve,auc
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import make_scorer

#########################Processing trainning data#######################
train_label = map(float, train_label)
X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.33, random_state=42)
X_train = np.array(X_train)
y_train = np.array(y_train)
X_test = np.array(X_test)
y_test = np.array(y_test)
train_data = np.array(train_data)
train_label = np.array(train_label)

############################Fitting model##############################
#param = [2,0.8,3000,0.05,6,0.05,0.8,1]
param = [3,0.8,3000,0.1,4,0.00,1,1]

print("fitting xgboost model using parameter ")
print(param)
gbm = xgb.XGBClassifier(max_depth=param[0], subsample=param[1],n_estimators=param[2], 
    learning_rate=param[3],nthread=500,seed=5,min_child_weight=param[4], gamma=param[5], 
    colsample_bytree=param[6], colsample_bylevel = param[7])
gbm.fit(train_data, train_label)
#504 features


with open('/home/amber/xg_final_all.pkl', 'wb+') as fid:
    cPickle.dump(gbm, fid) 
print("saving xg model all completed")

#####################Cross validating##############################
print("Cross validating xgboost 5 fold: ROC")
print("CV ROC")
gbm_eval = xgb.XGBClassifier(max_depth=param[0], subsample=param[1],n_estimators=param[2], 
    learning_rate=param[3],nthread=1000,seed=5,min_child_weight=param[4], gamma=param[5], 
    colsample_bytree=param[6],colsample_bylevel = param[7])
scores = cross_validation.cross_val_score(gbm_eval, train_data, train_label,cv = 5, n_jobs = 100,scoring = 'roc_auc')
print(np.mean(scores))
print(scores)

print("Validating set: Accuracy")
gbm_eval = xgb.XGBClassifier(max_depth=param[0], subsample=param[1],n_estimators=param[2], 
    learning_rate=param[3],nthread=500,seed=5,min_child_weight=param[4], gamma=param[5], 
    colsample_bytree=param[6],colsample_bylevel = param[7])
gbm_eval.fit(X_train,y_train)
accuracy = cross_validation.cross_val_score(gbm_eval, train_data, train_label,n_jobs = 6,cv = 5)
print(np.mean(accuracy))
print(accuracy)

#####################################################################
print("Sending email")

import smtplib

sender = 'yuyan.zhang.950310@gmail.com'
receivers = ['yuyan.zhang.950310@gmail.com']

message = """From: From Person <from@fromdomain.com>
To: To Person <to@todomain.com>
Subject: XG boost result

"""+"Model all Cross Validating result roc: "+str(scores)

try:
   smtpObj = smtplib.SMTP('localhost')
   smtpObj.sendmail(sender, receivers, message)         
   print "Successfully sent email"
except SMTPException:
   print "Error: unable to send email"



